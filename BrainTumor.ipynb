{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kKsYYDLQ0UR"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install imutils wandb\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OxVB1FRriAvd",
        "outputId": "212c5033-f9e9-4810-cfb5-baa954b1a384"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import itertools\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D,BatchNormalization, MaxPooling2D,Dropout,Flatten,Dense, Activation\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "%matplotlib inline\n",
        "init_notebook_mode(connected=True)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_SEED = 101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChewyTQUijAy"
      },
      "outputs": [],
      "source": [
        "!apt-get install tree\n",
        "clear_output()\n",
        "!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO\n",
        "!tree -d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep3t17zFo8ed"
      },
      "outputs": [],
      "source": [
        "IMG_PATH = '/content/drive/MyDrive/brain_tumor_dataset/'\n",
        "\n",
        "# split the data by train/val/test\n",
        "for CLASS in os.listdir(IMG_PATH):\n",
        "    if not CLASS.startswith('.'):\n",
        "        IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n",
        "        for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n",
        "            img = IMG_PATH + CLASS + '/' + FILE_NAME\n",
        "            if n<5:\n",
        "                shutil.copy(img, 'TEST/' + CLASS.upper() + '/' + FILE_NAME)\n",
        "            elif n<0.8*IMG_NUM:\n",
        "                shutil.copy(img, 'TRAIN/' + CLASS.upper() + '/' + FILE_NAME)\n",
        "            else:\n",
        "                shutil.copy(img, 'VAL/' + CLASS.upper() + '/' + FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMaB9mUqzkrv"
      },
      "outputs": [],
      "source": [
        "def load_data(dir_path, img_size=(100,100)):\n",
        "    X = []\n",
        "    y = []\n",
        "    i=0\n",
        "    labels = dict()\n",
        "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
        "        if not path.startswith('.'):\n",
        "            labels[i] = path\n",
        "            for file in os.listdir(dir_path + path):\n",
        "                if not file.startswith('.'):\n",
        "                    img = cv2.imread(dir_path + path + '/' + file)\n",
        "                    X.append(img)\n",
        "                    y.append(i)\n",
        "            i += 1\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f'{len(X)} images loaded from {dir_path} directory.')\n",
        "    return X, y, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtxw3unuzo6_"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = 'TRAIN/'\n",
        "TEST_DIR = 'TEST/'\n",
        "VAL_DIR = 'VAL/'\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "# use predefined function to load the image data into workspace\n",
        "X_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\n",
        "X_test, y_test, _  = load_data(TEST_DIR, IMG_SIZE)\n",
        "X_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob0qVsMkzxZw"
      },
      "outputs": [],
      "source": [
        "y = dict()\n",
        "y[0] = []\n",
        "y[1] = []\n",
        "for set_name in (y_train, y_val, y_test):\n",
        "    y[0].append(np.sum(set_name==0))\n",
        "    y[1].append(np.sum(set_name==1))\n",
        "trace0 = go.Bar(\n",
        "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
        "    y=y[0],\n",
        "    name='No',\n",
        "    marker=dict(color='#33cc33'),\n",
        "    opacity=0.7)\n",
        "trace1 = go.Bar(\n",
        "    x=['Train Set', 'Validation Set', 'Test Set'],\n",
        "    y=y[1],\n",
        "    name='Yes',\n",
        "    marker=dict(color='#ff3300'),\n",
        "    opacity=0.7)\n",
        "\n",
        "data = [trace0, trace1]\n",
        "layout = go.Layout(\n",
        "    title='Count of classes in each set',\n",
        "    xaxis={'title':'Set'},\n",
        "    yaxis={'title':'Count'}\n",
        ")\n",
        "fig = go.Figure(data,layout)\n",
        "iplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bYt0e0k02Vl"
      },
      "outputs": [],
      "source": [
        "def plot_samples(X,y,labels_dict, n=50):\n",
        "    \"\"\"\n",
        "        Create a gridplot for desired number of images (n) from specified set\n",
        "    \"\"\" \n",
        "    for index in range(len(labels_dict)):\n",
        "        imgs = X[np.argwhere(y==index)][:n]\n",
        "        j = 10\n",
        "        i = int(n/j)\n",
        "        \n",
        "        plt.figure(figsize=(15,6))\n",
        "        c = 1\n",
        "        for img in imgs:\n",
        "            plt.subplot(i,j,c)\n",
        "            plt.imshow(img[0])\n",
        "            \n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            c += 1\n",
        "        plt.suptitle('Tumor detected : {}'.format(labels_dict[index]))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDXVcZk81HKY"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train, y_train, labels, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai62fMP3V3qk"
      },
      "outputs": [],
      "source": [
        "def crop_imgs(set_name, add_pixels_value=0):\n",
        "    \"\"\"\n",
        "    Finds the extreme points on the image and crops the rectangular out of them\n",
        "    \"\"\"\n",
        "    set_new = []\n",
        "    for img in set_name:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # threshold the image, then perform a series of erosions +\n",
        "        # dilations to remove any small regions of noise\n",
        "        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "        thresh = cv2.erode(thresh, None, iterations=2)\n",
        "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "        # find contours in thresholded image, then grab the largest one\n",
        "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cnts = imutils.grab_contours(cnts)\n",
        "        c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "        # find the extreme points\n",
        "        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "        extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "        extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "        extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\n",
        "        ADD_PIXELS = add_pixels_value\n",
        "        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
        "        set_new.append(new_img)\n",
        "\n",
        "    return np.array(set_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI3Fs_PZV5UU"
      },
      "outputs": [],
      "source": [
        "X_train_crop = crop_imgs(set_name=X_train)\n",
        "X_val_crop = crop_imgs(set_name=X_val)\n",
        "X_test_crop = crop_imgs(set_name=X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNajHzasV9KA"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train_crop, y_train, labels, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVkb9KxNXUCo"
      },
      "outputs": [],
      "source": [
        "def save_new_images(x_set, y_set, folder_name):\n",
        "    i = 0\n",
        "    for (img, imclass) in zip(x_set, y_set):\n",
        "        if imclass == 0:\n",
        "            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)\n",
        "        else:\n",
        "            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4FziS-6XZxq"
      },
      "outputs": [],
      "source": [
        "# saving new images to the folder\n",
        "!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES VAL_CROP/NO\n",
        "\n",
        "save_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\n",
        "save_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\n",
        "save_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysx02G-dX7D1"
      },
      "outputs": [],
      "source": [
        "def preprocess_imgs(set_name, img_size):\n",
        "    \"\"\"\n",
        "    Resize and apply VGG-19 preprocessing\n",
        "    \"\"\"\n",
        "    set_new = []\n",
        "    for img in set_name:\n",
        "        img = cv2.resize(\n",
        "            img,\n",
        "            dsize=img_size,\n",
        "            interpolation=cv2.INTER_CUBIC\n",
        "        )\n",
        "        set_new.append(preprocess_input(img))\n",
        "    return np.array(set_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7LFhavbX-Jd"
      },
      "outputs": [],
      "source": [
        "X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\n",
        "X_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\n",
        "X_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQbzFv86YHwz"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train_prep,y_train,labels,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrjhQntxhsVs"
      },
      "outputs": [],
      "source": [
        "demo_datagen = ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.05,\n",
        "    height_shift_range = 0.05,\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.05,\n",
        "    brightness_range = [0.1,1.5],\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozjlvP70yC1W"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = 'TRAIN_CROP/'\n",
        "VAL_DIR = 'VAL_CROP/'\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    color_mode='rgb',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    VAL_DIR,\n",
        "    color_mode='rgb',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwPKtSxqyVCW"
      },
      "outputs": [],
      "source": [
        "from keras.applications import ResNet50V2\n",
        "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Az81cs87O7"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras import  regularizers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC8hJwM-9A_W",
        "outputId": "c79399d7-374b-4162-ce8a-9263875e51d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,155,969\n",
            "Trainable params: 131,585\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "height=224\n",
        "width=224\n",
        "\n",
        "\n",
        "\n",
        "base_model = VGG19(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(height,width,3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model2 = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation=\"relu\", kernel_initializer='he_normal',\n",
        "    kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzn-Qn0M9Cib"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss=\"binary_crossentropy\", \n",
        "               optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model/vgg19New1Model.h5', \n",
        "                                                monitor='val_accuracy', verbose=1, \n",
        "                                                mode='max',save_best_only=True)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", mode=\"max\",\n",
        "                                         restore_best_weights=True, patience=30)\n",
        "callbacks_list = [checkpoint,early]\n",
        "\n",
        "history = model2.fit(train_generator, \n",
        "           validation_data=validation_generator,\n",
        "           epochs=35,\n",
        "           shuffle=True,\n",
        "           verbose=True,\n",
        "           callbacks=callbacks_list\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8UeoJGv2mcF"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "test_predictions = model2.predict(X_test_prep)\n",
        "\n",
        "# Evaluate the model's accuracy on the test set\n",
        "accuracy = accuracy_score(labels, test_predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zAQTiQp7jjt"
      },
      "outputs": [],
      "source": [
        "test_dir = 'TEST_CROP/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k55l12cZ9DDM"
      },
      "outputs": [],
      "source": [
        "test_genera = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        batch_size=16,\n",
        "        color_mode=\"rgb\",\n",
        "        target_size=IMG_SIZE,\n",
        "        class_mode='binary',\n",
        "        seed=RANDOM_SEED\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wNiZ-at5aPj"
      },
      "outputs": [],
      "source": [
        "train_result = model2.evaluate(train_generator)\n",
        "val_result = model2.evaluate(validation_generator)\n",
        "test_result = model2.evaluate(test_genera)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}